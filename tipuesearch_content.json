{"pages":[{"title":"James C. Loach","text":"I'm a data scientist and physicist with broad expertise in analysis, modeling, and hardware development. I have undergraduate (MPhys, 1st class) and postgraduate (Ph.D., Particle Physics) degrees from the University of Oxford, and I'm a member of Chinese 1000 Young Talents Plan (青年千人计划). Until recently, I was a professor at Shanghai Jiao Tong University (上海交通大学). Right now, I work for Senseye as a data scientist developing prognostics algorithms. I also have a small Chinese language edtech startup called Sinophenia . My CV is on LinkedIn and you can contact me at james.loach@gmail.com . Skills Software & analysis Regression and classification on complex data sets using machine learning techniques and traditional physics approaches Data analysis and modeling using the python stack (pandas, numpy, scipy, scikit-learn, etc.) Data visualization and production of high-quality graphics (matplotlib, D3.js, Illustrator etc.) Full-stack web development (flask, pelican, bootstrap, JavaScript, etc.) SQL and NoSQL databases (Postgresql, CouchDB) Full-stack Monte Carlo physics simulation Hardware & engineering Expert in ultra-low radioactivity material science HPGe detector gamma ray spectroscopy, including crystal instrumentation and development of custom high-performance electronics Cherenkov and two-phase xenon detector spectroscopy Micro-fabrication techniques Curriculum Vitae Education Ph.D., Particle Physics, University of Oxford (2003-2008) Thesis: Measuring the Flux of 8 B Solar Neutrinos Using the Sudbury Neutrino Observatory (SNO) MPhys, University of Oxford , Physics, 1st Class Hons. (1999-2003) Thesis: A Numerical Study of Vertical Propagation of Planetary Waves in the Stratosphere Professional experience Data Scientist , Senseye Ltd. (2017-) Founder & Director , Sinophenia Ltd. (2016-) Assistant Professor , Shanghai Jiao Tong University (上海交通大学) (2013-2016) Postdoctoral Research Scholar , Lawrence Berkeley National Laboratory (2008-2012) College Lecturer , Keble College, University of Oxford (2004-2006) Graduate Research Student , University of Oxford (2003-2008) Summer Student , CERN (2002) Logistics Engineer , Denso Manufacturing UK Ltd. (1998-1999) Awards Breakthrough Prize in Fundamental Physics (part share) (2016) Department award for undergraduate teaching (2015) National Science Foundation of China grant (2014) China 1000 Young Talents Plan (青年千人计划) (2012) Academic prizes, Somerville College, Oxford (2000-2003 ) Beilby academic scholarship, Somerville College, Oxford (2000) Publications Search for Zero-Neutrino Double Beta Decay in 76 Ge with the Majorana Demonstrator C.E. Aalseth et al., submitted to Phys. Rev. Lett. (2017). The Search for Neutron-antineutron Oscillations at the Sudbury Neutrino Observatory B. Aharmim et al., accepted for publication by Phys. Rev. D (2017). Finding Something to Read: Intelligibility, Readability and Learner Chinese Texts J.C Loach, submitted to ITL - International Journal of Applied Linguistics (2017). Optimizing the Learning Order of Chinese Characters Using a Novel Topological Sort Algorithm J.C. Loach and J. Wang, PLoS ONE 11(10): e0163623 (2016). A Database for Storing the Results of Material Radiopurity Measurements J.C. Loach et al., Nucl. Instr. Meth. A 839 (2016). The Majorana Demonstrator Radioassay Program N. Abgrall et al., Nucl. Instr. Meth. A 828 (2016). Low-background Temperature Sensors Fabricated on Parylene Substrates A. Dhar et al., J. Inst. 10 P12002 (2015). The Majorana Parts Tracking Database N. Abgrall et al., Nucl. Instr. Meth. A 779 (2015). The Majorana Demonstrator Neutrinoless Double-Beta Decay Experiment N. Abgrall et al., Adv. High Ener. Phys. 2014, 365432 (2014). A Search for Astrophysical Burst Signals at the Sudbury Neutrino Observatory B. Aharmim et al., Astropart. Phys., 55, 1 (2014). Combined Analysis of all Three Phases of Solar Neutrino Data from the Sudbury Neutrino Observatory B. Aharmim et al., Phys. Rev. C 88, 025501 (2013). Measurement of the v e and Total 8 B Solar Neutrino Fluxes with the Sudbury Neutrino Observatory Phase-III Data Set B. Aharmim et al., Phys. Rev. C 87, 015502 (2013). Characteristics of Signals Originating Near the Lithium-Diffused N+ Contact of High Purity Germanium P-Type Point Contact Detectors E. Aguayo et al., Nucl. Inst. Meth. A 701, 176 (2012). Determining the Drift Time of Charge Carrier in P-Type Point-Contact HPGe Detector R.D. Martin et al., Nucl. Instr. Meth. A 678, 98 (2012). Full Simulation of the Sudbury Neutrino Observatory Proportional Counters B. Beltran et al., New J. Phys. 13 073006 (2011). Astroparticle Physics with a Customized Low-Background Broad Energy Germanium Detector C.E. Aalseth et al., Nucl. Instr. Meth. A 652, 692 (2011). Low Multiplicity Burst Search at the Sudbury Neutrino Observatory B. Aharmim et al., ApJ 728, 83 (2011). The Calibration of the Sudbury Neutrino Observatory Using Uniformly Distributed Radioactive Sources K. Boudjemline et al., Nucl. Inst. Meth. A 620, 171 (2010). Low Energy Threshold Analysis of the Phase I and Phase II Data Sets of the Sudbury Neutrino Observatory B. Aharmim et al., Phys. Rev. C81, 055504 (2010). Searches for High Frequency Variations in the 8 B Solar Neutrino Flux at the Sudbury Neutrino Observatory B. Aharmim et al., ApJ 710, 540 (2010). Measurement of the Cosmic Ray and Neutrino-Induced Muon Flux at the Sudbury Neutrino Observatory B. Aharmim et al., Phys. Rev. D80, 012001 (2009). An Independent Measurement of the Total Active 8 B Solar Neutrino Flux Using an Array of 3 He Proportional Counters at the Sudbury Neutrino Observatory B. Aharmim et al., Phys. Rev. Lett. 101, 111301 (2008). An Array of Low-background 3 He Proportional Counters for the Sudbury Neutrino Observatory J.F. Amsbaugh et al., Nucl. Instr. Meth. A579 (2007). Measurement of the υ e and total 8 B Solar Neutrino Fluxes with the Sudbury Neutrino Observatory Phase I Data Set B. Aharmim et al., Phys. Rev. C75, 045502 (2007). A Search for Neutrinos from the Solar hep Reaction and the Diffuse Supernova Neutrino Background with the Sudbury Neutrino Observatory B. Aharmim et al., ApJ 653, 1545 (2006). A Search for Periodicities in the 8 B Solar Neutrino Flux Measured by the Sudbury Neutrino Observatory B. Aharmim et al., Phys. Rev. D72, 052010 (2005). Electron Energy Spectra, Fluxes, and Day-night Asymmetries of 8 B Solar Neutrinos from Measurements with NaCl Dissolved in the Heavy-water Detector at the Sudbury Neutrino Observatory B. Aharmim et al., Phys. Rev. C72, 055502 (2005). Select conference proceedings The Majorana Low-noise Low-background Front-end Electronics N. Abgrall et al., Physics Procedia 61 (2015). Neutron Production by Cosmic Ray Muons at the Sudbury Neutrino Observatory J.C. Loach et al., Nuclear Physics B - Proceedings Supplements 229-232 (2012). Low-noise Low-Mass Front End Electronics for Low-background Physics Experiments Using Germanium Detectors P. Barton et al., Proceedings of the IEEE Nuclear Science Symposium and Medical Imaging Conference (2011). Seminars and colloquia Southern Methodist University, Dallas, TX (2012) Rarest of Decays: Neutrinoless Double Beta Decay with Germanium University of Washington, Seattle, WA (2012) Rarest of Decays: Germanium & the Search for Neutrinoless Double Beta Decay (colloquium) Academia Sinica, Taipei, Taiwan (2012) Mining the Heavens: Adventures with Solar Neutrinos (colloquium) Academia Sinica, Taipei, Taiwan (2012) Germanium & the Search for Neutrinoless Double Beta Decay University of Hong Kong, Hong Kong, PRC (2011) Neutrinoless Double Beta Decay: the Golden Age? Lawrence Berkeley National Laboratory, Berkeley, CA (2011) KATRIN - a Direct Neutrino Mass Measurement University of Oxford, Oxford, UK (2010) The Majorana Demonstrator - Towards a Tonne-Scale Ge Experiment Brown University, Providence, RI (2010) Lowering the Energy Threshold at the Sudbury Neutrino Observatory MPIK Heidelberg, Heidelberg, Germany (2010. Lowering the Energy Threshold at the Sudbury Neutrino Observatory Lawrence Berkeley National Laboratory, Berkeley, CA (2010) Lowering the Energy Threshold at the Sudbury Neutrino Observatory Lawrence Berkeley National Laboratory, Berkeley, CA (2008) Results from the Final Phase of SNO Lawrence Livermore National Laboratory, Livermore, CA (2008) The Final Phase of SNO Stanford University, Palo Alto, CA (2008) The Final Phase of SNO","tags":"pages","url":"http://jamesloach.com/pages/about.html","loc":"http://jamesloach.com/pages/about.html"},{"title":"Map making","text":"I like to draw maps and am happy to consider commissions. You can contact me at james.loach@gmail.com","tags":"pages","url":"http://jamesloach.com/pages/maps.html","loc":"http://jamesloach.com/pages/maps.html"},{"title":"Photography","text":"I like to take photos, occasionally as one third of Three Fish Photography .","tags":"pages","url":"http://jamesloach.com/pages/photography.html","loc":"http://jamesloach.com/pages/photography.html"},{"title":"Apply PCA to a DataFrame","text":"import pandas as pd from pandas import DataFrame import numpy as np from sklearn.decomposition import PCA Create a DataFrame full of random numbers. df = pd . DataFrame ( data = np . random . normal ( 0 , 1 , ( 50 , 8 ))) df . head () .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } 0 1 2 3 4 5 6 7 0 -0.314008 -1.090192 -0.920020 -0.559545 0.775226 -0.882474 1.050049 -0.092116 1 -0.145504 -0.297851 0.140186 -0.724637 0.558747 -0.708013 -0.555629 0.653227 2 0.711590 -0.215502 -0.266352 -1.058049 -0.324418 0.929751 0.352552 -0.256500 3 0.625027 -0.725645 0.477974 -1.182262 1.435128 -0.673370 -1.112910 0.354148 4 1.335500 -0.488708 -0.131384 -0.581381 -0.451392 0.149943 -0.250088 -0.011798 Fit the PCA . pca = PCA ( n_components = 4 ) pca . fit ( df ) PCA(copy=True, iterated_power='auto', n_components=4, random_state=None, svd_solver='auto', tol=0.0, whiten=False) Apply the transformation and convert the result into a DataFrame . columns = [ 'pca_ %i ' % i for i in range ( 4 )] df_pca = DataFrame ( pca . transform ( df ), columns = columns , index = df . index ) df_pca . head () .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } pca_0 pca_1 pca_2 pca_3 0 -0.546917 0.506951 -1.042971 0.287119 1 -0.054910 -0.217007 -0.539264 0.457777 2 0.908084 -0.113016 -0.602685 -1.009475 3 -0.168224 -1.419395 -1.216016 0.196382 4 0.678731 -0.605830 -0.057639 -0.428901 If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/sklearn_pca_to_dataframe.html","loc":"http://jamesloach.com/python/sklearn_pca_to_dataframe.html"},{"title":"Count the number of NaN's","text":"from pandas import DataFrame import numpy as np Create a pandas DataFrame . df = DataFrame ({ 'a' : [ 8 , np . nan , 23 ], 'b' : [ 7 , 8 , 4 ], 'c' : [ 400 , 83 , 98 ]}, index = [ \"one\" , \"two\" , \"three\" ]) df .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } a b c one 8.0 7 400 two NaN 8 83 three 23.0 4 98 Count the number of NaN 's in each column. df . isnull () . sum () a 1 b 0 c 0 dtype: int64 Count the number of NaN 's in each row. df . isnull () . sum ( axis = 1 ) one 0 two 1 three 0 dtype: int64 If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/number_nan.html","loc":"http://jamesloach.com/python/number_nan.html"},{"title":"Converting DataFrames to and from R","text":"from pandas import DataFrame from rpy2.robjects import pandas2ri pandas2ri . activate () Create a pandas DataFrame. df = DataFrame ({ 'a' : [ 8 , 21 , 23 ], 'b' : [ 7 , 8 , 4 ], 'c' : [ 400 , 83 , 98 ]}, index = [ \"one\" , \"two\" , \"three\" ]) df .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } a b c one 8 7 400 two 21 8 83 three 23 4 98 Explicitly convert into an R data frame. r_df = pandas2ri . py2ri ( df ) type ( r_df ) rpy2.robjects.vectors.DataFrame Explicitly convert back into a pandas DataFrame. df = pandas2ri . ri2py ( r_df ) df .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } a b c one 8 7 400 two 21 8 83 three 23 4 98 If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/pandas2ri.html","loc":"http://jamesloach.com/python/pandas2ri.html"},{"title":"Calling R using rmagic","text":"In a Jupyter notebook you can use rmagic which is a part of rpy2 . import rpy2 % load_ext rpy2 . ipython import numpy as np Line magic %R is line magic and returns values to python. % R X = c ( 1 , 2 , 3 , 4 ); mean ( X ) array([ 2.5]) a = % R X = c ( 1 , 2 , 3 , 4 ); mean ( X ) print ( a ) [ 2.5] Cell magic %%R is cell magic. It returns nothing by default. %% R X = c ( 1 , 2 , 3 , 4 , 5 , 6 ) summary ( X ) Min. 1st Qu. Median Mean 3rd Qu. Max. 1.00 2.25 3.50 3.50 4.75 6.00 The flags -w and -h can be used to control size of any graphics ( -u specifies the unit). %% R - w 300 - h 300 - u px X = c ( 1 , 2 , 3 , 4 , 5 , 6 ) Y = X ** 2 plot ( X , Y ) Passing objects back and forth This can be done using the -i and -o flags. Z = np . array ([ 1 , 2 , 3 , 4 ]) % R - i Z mean ( Z ) array([ 2.5]) % R - o W W = Z * mean ( Z ) array([ 2.5, 5. , 7.5, 10. ]) Use %Rpull to pull back variables from R. _ = % R x = c ( 1 , 2 , 3.8 ); y = c ( 6 , 7 , 8 ); z = c ( 'a' , 'b' , 4 ) % Rpull x y z print ( x ) print ( y ) print ( z ) [ 1. 2. 3.8] [ 6. 7. 8.] ['a' 'b' '4'] Use %Rget to pull back objects. dtype = [( 'x' , '<i4' ), ( 'y' , '<f8' )] data = np . array ([( 1 , 40.5 ), ( 2 , 31.5 ), ( 3 , 26.1 ), ( 4 , 53.4 )], dtype = dtype ) % R - i data % Rget data .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } x y 1 1 40.5 2 2 31.5 3 3 26.1 4 4 53.4 If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/rmagic.html","loc":"http://jamesloach.com/python/rmagic.html"},{"title":"Iterating through rows in a DataFrame","text":"from pandas import DataFrame iterrows Returns a generator that iterates over rows. Each row is returns as a Series. df = DataFrame ({ 'alpha' : [ 0.11 , 0.18 , 0.05 , - 0.01 , - 0.42 ], 'beta' : [ 16.8 , 27.6 , - 23.4 , 4.0 , 15.1 ], 'cls' : [ 'a' , 'b' , 'b' , 'a' , 'b' ]}) for i , event in df . iterrows (): print ( i , event [ 'alpha' ]) 0 0.11 1 0.18 2 0.05 3 -0.01 4 -0.42 itertuples Returns a generator that iterates over rows. Each row is returned as a namedtuple. df = DataFrame ({ 'alpha' : [ 0.11 , 0.18 , 0.05 , - 0.01 , - 0.42 ], 'beta' : [ 16.8 , 27.6 , - 23.4 , 4.0 , 15.1 ], 'cls' : [ 'a' , 'b' , 'b' , 'a' , 'b' ]}) for event in df . itertuples ( index = False ): alpha , beta , cls = event print ( alpha , beta ) for event in df . itertuples ( index = False , name = 'event' ): prod = event . alpha * event . beta 0.11 16.8 0.18 27.6 0.05 -23.4 -0.01 4.0 -0.42 15.1 If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/iterating_through_rows.html","loc":"http://jamesloach.com/python/iterating_through_rows.html"},{"title":"Smoothing with a Savitzky-Golay filter","text":"import scipy.signal import numpy as np import matplotlib.pyplot as plt x = np . linspace ( 0 , 2 * np . pi , 100 ) y_noise = np . sin ( - x ) + ( np . random . random ( 100 ) - 0.5 ) * 0.5 y_true = np . sin ( - x ) y_sg = scipy . signal . savgol_filter ( y_noise , 51 , 3 ) plt . figure ( figsize = ( 9 , 6 )) plt . plot ( x , y_true , color = 'k' , alpha = 0.5 ) plt . plot ( x , y_noise , color = 'orange' ) plt . plot ( x , y_sg , color = 'r' ) plt . show () If you spot any errors please let me know on twitter .","tags":"data_analysis","url":"http://jamesloach.com/data_analysis/savitzky_golay.html","loc":"http://jamesloach.com/data_analysis/savitzky_golay.html"},{"title":"scikit-learn scalers in DataFrames","text":"import pandas as pd from sklearn.preprocessing import StandardScaler scaler = StandardScaler () df = pd . DataFrame ({ 'alpha' : [ 0.11 , 0.18 , 0.05 , - 0.01 , - 0.42 ], 'beta' : [ 16.8 , 27.6 , - 23.4 , 4.0 , 15.1 ], 'cls' : [ 'a' , 'b' , 'b' , 'a' , 'b' ]}) df [[ 'alpha' , 'beta' ]] = scaler . fit_transform ( df [[ 'alpha' , 'beta' ]]) df .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } alpha beta cls 0 0.607625 0.504570 a 1 0.939920 1.125225 b 2 0.322801 -1.805647 b 3 0.037977 -0.231022 a 4 -1.908323 0.406874 b If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/sklearn_scalers_in_dataframes.html","loc":"http://jamesloach.com/python/sklearn_scalers_in_dataframes.html"},{"title":"matplotlib basics","text":"import matplotlib.pyplot as plt import numpy as np Basic example x = np . arange ( 0 , 10 , 0.2 ) y1 , y2 = np . sin ( x ), np . cos ( x ) fig , ax = plt . subplots ( 2 , figsize = ( 9 , 6 )) ax [ 0 ] . plot ( x , y1 ) ax [ 1 ] . plot ( x , y2 ) plt . show () Two interfaces x = np . arange ( 0 , 10 , 0.2 ) y = np . sin ( x ) OO API fig , ax = plt . subplots ( 1 , figsize = ( 9 , 5 )) ax . plot ( x , y ) ax . set_xlim ( 0 , 6 ) ax . set_ylabel ( 'Value' ) plt . show () matlab-style API plt . figure ( figsize = ( 9 , 5 )) plt . plot ( x , y ) plt . xlim ( 0 , 6 ) plt . ylabel ( 'Value' ) plt . show () In a Jupyter notebook import matplotlib.pyplot as plt % matplotlib inline If you spot any errors please let me know on twitter .","tags":"misc","url":"http://jamesloach.com/misc/matplotlib_basics.html","loc":"http://jamesloach.com/misc/matplotlib_basics.html"},{"title":"Making a script executable","text":"Add the following to the first line of the .py file. #!/usr/bin/env python3 Then change permissions. chmod +x script.py If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/executable-script.html","loc":"http://jamesloach.com/python/executable-script.html"},{"title":"Reset an index","text":"import pandas as pd Use reset_index to create a new sequential index. df = pd . DataFrame ([( 'S7003' , 24.1 ), ( 'S2344' , 14.2 ), ( 'B3404' , 17.7 ), ( 'E6911' , 11.1 )], index = [ '1' , '3' , '5' , '6' ], columns = ( 'id' , 'age' )) df .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } id age 1 S7003 24.1 3 S2344 14.2 5 B3404 17.7 6 E6911 11.1 The default behavior to move the existing index to a column. df . reset_index () .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } index id age 0 1 S7003 24.1 1 3 S2344 14.2 2 5 B3404 17.7 3 6 E6911 11.1 But the original index can also be dropped. df . reset_index ( drop = True ) .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; } id age 0 S7003 24.1 1 S2344 14.2 2 B3404 17.7 3 E6911 11.1 If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/reset_index.html","loc":"http://jamesloach.com/python/reset_index.html"},{"title":"Location of installed packages","text":"Run from the command line: python -c \"from distutils.sysconfig import get_python_lib; print(get_python_lib())\" If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/installed-package-location.html","loc":"http://jamesloach.com/python/installed-package-location.html"},{"title":"pickle","text":"import pickle pickle is used to serialize and deserialize python objects. some_object = { 'title' : 'Dunkirk' , 'length' : '1:46' , 'certificate' : '12A' } pickle . dump ( some_object , open ( 'movie.pkl' , 'wb' )) pickle . load ( open ( 'movie.pkl' , 'rb' )) If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/pickle.html","loc":"http://jamesloach.com/python/pickle.html"},{"title":"Make a dummy index column","text":"import pandas as pd Get a suitable data set and put it in a DataFrame. from sklearn.datasets import load_boston boston = load_boston () df = pd . DataFrame ( boston . data , columns = boston [ 'feature_names' ]) Add a dummy index column. df . insert ( 0 , 'ID' , 100000 + df . index ) df . head ( 10 ) ID CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT 0 100000 0.00632 18.0 2.31 0.0 0.538 6.575 65.2 4.0900 1.0 296.0 15.3 396.90 4.98 1 100001 0.02731 0.0 7.07 0.0 0.469 6.421 78.9 4.9671 2.0 242.0 17.8 396.90 9.14 2 100002 0.02729 0.0 7.07 0.0 0.469 7.185 61.1 4.9671 2.0 242.0 17.8 392.83 4.03 3 100003 0.03237 0.0 2.18 0.0 0.458 6.998 45.8 6.0622 3.0 222.0 18.7 394.63 2.94 4 100004 0.06905 0.0 2.18 0.0 0.458 7.147 54.2 6.0622 3.0 222.0 18.7 396.90 5.33 5 100005 0.02985 0.0 2.18 0.0 0.458 6.430 58.7 6.0622 3.0 222.0 18.7 394.12 5.21 6 100006 0.08829 12.5 7.87 0.0 0.524 6.012 66.6 5.5605 5.0 311.0 15.2 395.60 12.43 7 100007 0.14455 12.5 7.87 0.0 0.524 6.172 96.1 5.9505 5.0 311.0 15.2 396.90 19.15 8 100008 0.21124 12.5 7.87 0.0 0.524 5.631 100.0 6.0821 5.0 311.0 15.2 386.63 29.93 9 100009 0.17004 12.5 7.87 0.0 0.524 6.004 85.9 6.5921 5.0 311.0 15.2 386.71 17.10 Another way to do it, is to reset the index. df = pd . DataFrame ( boston . data , columns = boston [ 'feature_names' ]) df = df . reset_index () df . head ( 10 ) index CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT 0 0 0.00632 18.0 2.31 0.0 0.538 6.575 65.2 4.0900 1.0 296.0 15.3 396.90 4.98 1 1 0.02731 0.0 7.07 0.0 0.469 6.421 78.9 4.9671 2.0 242.0 17.8 396.90 9.14 2 2 0.02729 0.0 7.07 0.0 0.469 7.185 61.1 4.9671 2.0 242.0 17.8 392.83 4.03 3 3 0.03237 0.0 2.18 0.0 0.458 6.998 45.8 6.0622 3.0 222.0 18.7 394.63 2.94 4 4 0.06905 0.0 2.18 0.0 0.458 7.147 54.2 6.0622 3.0 222.0 18.7 396.90 5.33 5 5 0.02985 0.0 2.18 0.0 0.458 6.430 58.7 6.0622 3.0 222.0 18.7 394.12 5.21 6 6 0.08829 12.5 7.87 0.0 0.524 6.012 66.6 5.5605 5.0 311.0 15.2 395.60 12.43 7 7 0.14455 12.5 7.87 0.0 0.524 6.172 96.1 5.9505 5.0 311.0 15.2 396.90 19.15 8 8 0.21124 12.5 7.87 0.0 0.524 5.631 100.0 6.0821 5.0 311.0 15.2 386.63 29.93 9 9 0.17004 12.5 7.87 0.0 0.524 6.004 85.9 6.5921 5.0 311.0 15.2 386.71 17.10 If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/dummy_index.html","loc":"http://jamesloach.com/python/dummy_index.html"},{"title":"Unique values in a column","text":"import pandas as pd Get a suitable data set and put it in a DataFrame. from sklearn.datasets import load_boston boston = load_boston () df = pd . DataFrame ( boston . data , columns = boston [ 'feature_names' ]) Get the unique values in a column. df [ 'CHAS' ] . unique () array([ 0., 1.]) See how many entries with each value. df [ 'CHAS' ] . value_counts () 0.0 471 1.0 35 Name: CHAS, dtype: int64 If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/unique_values.html","loc":"http://jamesloach.com/python/unique_values.html"},{"title":"Renaming columns","text":"import pandas as pd Set column names on reading a data file. column_names = [ 'sepal_length' , 'sepal_width' , 'petal_length' , 'petal_width' , 'target' ] iris = pd . read_csv ( '../data/iris.csv' , names = column_names ) iris . head () sepal_length sepal_width petal_length petal_width target 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa Set column names for an existing dataframe. iris = pd . read_csv ( '../data/iris.csv' ) column_names = [ 'sepal_length' , 'sepal_width' , 'petal_length' , 'petal_width' , 'target' ] iris . columns = column_names iris . head () sepal_length sepal_width petal_length petal_width target 0 4.9 3.0 1.4 0.2 Iris-setosa 1 4.7 3.2 1.3 0.2 Iris-setosa 2 4.6 3.1 1.5 0.2 Iris-setosa 3 5.0 3.6 1.4 0.2 Iris-setosa 4 5.4 3.9 1.7 0.4 Iris-setosa Rename individual columns. iris . rename ( columns = { 'target' : 'species' }, inplace = True ) iris . head () sepal_length sepal_width petal_length petal_width species 0 4.9 3.0 1.4 0.2 Iris-setosa 1 4.7 3.2 1.3 0.2 Iris-setosa 2 4.6 3.1 1.5 0.2 Iris-setosa 3 5.0 3.6 1.4 0.2 Iris-setosa 4 5.4 3.9 1.7 0.4 Iris-setosa Rename with a function. iris . rename ( columns = lambda x : 'col_' + x , inplace = True ) iris . head () col_sepal_length col_sepal_width col_petal_length col_petal_width col_species 0 4.9 3.0 1.4 0.2 Iris-setosa 1 4.7 3.2 1.3 0.2 Iris-setosa 2 4.6 3.1 1.5 0.2 Iris-setosa 3 5.0 3.6 1.4 0.2 Iris-setosa 4 5.4 3.9 1.7 0.4 Iris-setosa Get column names. print ( iris . columns ) Index(['col_sepal_length', 'col_sepal_width', 'col_petal_length', 'col_petal_width', 'col_species'], dtype='object') If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/renaming_columns.html","loc":"http://jamesloach.com/python/renaming_columns.html"},{"title":"Rolling window calculations","text":"import pandas as pd from pandas import DataFrame , Series pd . options . display . max_rows = 10 import numpy as np import matplotlib.pyplot as plt % matplotlib inline plt . style . use ( 'seaborn' ) Make a noisy time series. lin = np . linspace ( - 1 , 1 , 100 ) noise = np . random . normal ( 0 , 0.5 , 100 ) signal = Series ( lin + noise ) signal . plot () plt . show () Plot the mean for a rolling window containing 10 measurements. signal . rolling ( 10 ) . mean () . plot () plt . show () The first 9 measurements are NaN . signal . rolling ( 10 ) . mean () . head ( 10 ) 0 NaN 1 NaN 2 NaN 3 NaN 4 NaN 5 NaN 6 NaN 7 NaN 8 NaN 9 -0.856827 dtype: float64 If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/rolling_windows.html","loc":"http://jamesloach.com/python/rolling_windows.html"},{"title":"deque","text":"from collections import deque A deque (or double-ended queue) is like a list, but supports efficient and convenient appends and pops at either end. a = deque ( range ( 11 ), maxlen = 7 ) print ( a ) deque([4, 5, 6, 7, 8, 9, 10], maxlen=7) Note that the maxlen parameter constrains the length of the deque and causes excess items to be pushed off the left. Use pop to get items from either end. x = a . pop () y = a . popleft () a deque([5, 6, 7, 8, 9]) Use rotate to rotate the deque in either direction. a . rotate ( 2 ) # to the right a deque([8, 9, 5, 6, 7]) a . rotate ( - 2 ) # to the left a deque([5, 6, 7, 8, 9]) Use append to append items to either end. a . appendleft ( 0 ) a . append ( 6 ) a deque([0, 5, 6, 7, 8, 9, 6]) Use extend to extend the deque in either directions using items from an iterable. The length of the deque remains unchanged and excess items are 'pushed off' from the opposite end. a . extendleft ([ - 3 , - 2 , - 1 ]) # items pushed off the right a deque([-1, -2, -3, 0, 5, 6, 7]) a . extend ([ 4 , 5 , 6 ]) # items pushed off the left a deque([0, 5, 6, 7, 4, 5, 6]) If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/deque.html","loc":"http://jamesloach.com/python/deque.html"},{"title":"Generator expressions","text":"A genexp is a convenient way to make a generator. larkin_poems = [ 'church going' , 'the whitsun weddings' , 'an arundel tomb' , 'aubade' ] title = ( poem . title () for poem in larkin_poems ) print ( next ( title )) print ( next ( title )) print ( next ( title )) Church Going The Whitsun Weddings An Arundel Tomb Build sets and dicts without building intermediate lists. a = set ( char for char in 'Loveliest of trees, the cherry now' ) b = dict (( x , x ** 2 ) for x in range ( 9 )) Sometimes avoiding the intermediate lists can save significant amounts of memory (relative to listcomps). sum_listcomp = sum ([ x * x for x in range ( 10000000 )]) sum_genexp = sum ( x * x for x in range ( 10000000 )) If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/genexps.html","loc":"http://jamesloach.com/python/genexps.html"},{"title":"namedtuple","text":"from collections import namedtuple A namedtuple can be used as a lightweight class (with a class name and attribute names). Crayon = namedtuple ( 'Crayon' , 'code color' ) red = Crayon ( 121 , 'pale geranium lake' ) yellow = Crayon ( 105 , 'light cadmium yellow' ) green = Crayon ( 112 , 'leaf green' ) blue = Crayon ( 120 , 'ultramarine' ) print ( yellow ) Crayon(code=105, color='light cadmium yellow') print ( red . code ) print ( blue . color ) print ( yellow [ 0 ]) 121 ultramarine 105 Crayon . _fields ('code', 'color') for key , value in green . _asdict () . items (): print ( key , ':' , value ) code : 112 color : leaf green Instantiate using a tuple. new_crayon = ( 141 , 'Delft blue' ) blue_2 = Crayon . _make ( new_crayon ) blue_2 = Crayon ( * new_crayon ) If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/namedtuple.html","loc":"http://jamesloach.com/python/namedtuple.html"},{"title":"Slices","text":"slice objects A slice object can be passed in place of an index. cut = slice ( 4 , 11 ) text = \"The unknown unknown\" text [ cut ] 'unknown' Useful in processing strings. field_1 = \"Bananas, oranges 101 134,23 £11,23\" field_2 = \"Apples, pineapples 102 234,53 £14,13\" field_3 = \"Kiwi fruit 103 13,03 £2,99\" DESCRIPTION = slice ( 0 , 22 ) print ( field_1 [ DESCRIPTION ]) print ( field_3 [ DESCRIPTION ]) Bananas, oranges Kiwi fruit Assigning to slices a = list ( range ( 7 )) a [0, 1, 2, 3, 4, 5, 6] a [ 2 : 4 ] = [ 12 , 14 ] a [0, 1, 12, 14, 4, 5, 6] del a [ 4 :] a [0, 1, 12, 14] If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/slices.html","loc":"http://jamesloach.com/python/slices.html"},{"title":"Sorting sequences","text":"greeks = [ 'Aeschylus' , 'Sophocles' , 'Socrates' , 'Euripides' , 'Phrynichus' ] Get a sorted copy. out = sorted ( greeks ) print ( greeks ) print ( out ) ['Aeschylus', 'Sophocles', 'Socrates', 'Euripides', 'Phrynichus'] ['Aeschylus', 'Euripides', 'Phrynichus', 'Socrates', 'Sophocles'] Sort in place. greeks . sort () print ( greeks ) ['Aeschylus', 'Euripides', 'Phrynichus', 'Socrates', 'Sophocles'] Change the sort direction. sorted ( greeks , reverse = True ) ['Sophocles', 'Socrates', 'Phrynichus', 'Euripides', 'Aeschylus'] Provide a function and sort by its output. sorted ( greeks , key = len ) ['Socrates', 'Aeschylus', 'Euripides', 'Sophocles', 'Phrynichus'] sorted ( greeks , key = lambda x : x [ 1 ]) ['Aeschylus', 'Phrynichus', 'Socrates', 'Sophocles', 'Euripides'] Unlike sort , sorted can also be applied to immutable sequences (returning a list). a = ( 11 , 4 , 15 , 6 , 13 , 12 , 4 , 5 , 1 , 0 ) sorted ( a ) [0, 1, 4, 4, 5, 6, 11, 12, 13, 15] If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/sorting_sequences.html","loc":"http://jamesloach.com/python/sorting_sequences.html"},{"title":"map and filter","text":"map Maps one iterable onto another. result = map ( lambda x : x ** 2 , range ( 7 )) list ( result ) [0, 1, 4, 9, 16, 25, 36] a = range ( 7 ) b = range ( 3 , 10 ) result = map ( lambda x , y : y ** 2 - x , a , b ) list ( result ) [9, 15, 23, 33, 45, 59, 75] These would be neater using list comprehensions. print ([ x ** 2 for x in range ( 7 )]) print ([ y ** 2 - x for x , y in zip ( range ( 7 ), range ( 3 , 10 ))]) [0, 1, 4, 9, 16, 25, 36] [9, 15, 23, 33, 45, 59, 75] Or as generator expressions. result_1 = ( x ** 2 for x in range ( 7 )) result_2 = ( y ** 2 - x for x , y in zip ( range ( 7 ), range ( 3 , 10 ))) print ( list ( result_1 )) print ( list ( result_2 )) [0, 1, 4, 9, 16, 25, 36] [9, 15, 23, 33, 45, 59, 75] Thus map is a pretty redundant function. filter Returns items for which the function evaluates True . result = filter ( lambda x : x % 2 , range ( 13 )) list ( result ) [1, 3, 5, 7, 9, 11] result = filter ( lambda x : x > 3 , range ( 13 )) list ( result ) [4, 5, 6, 7, 8, 9, 10, 11, 12] Combining map and filter You can map items and then filter the result. result = filter ( lambda x : x % 2 , map ( lambda x : x - 11 , range ( 21 ))) list ( result ) [-11, -9, -7, -5, -3, -1, 1, 3, 5, 7, 9] If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/map_and_filter.html","loc":"http://jamesloach.com/python/map_and_filter.html"},{"title":"Nested tuples","text":"A nested tuple can be easily unpacked. buried_treasure = [( 'Gold plate' , 1145 , ( 34.501 , - 45.234 )), ( 'Sword' , 1156 , ( 34.545 , - 45.101 )), ( 'Ring' , 1323 , ( 34.547 , - 45.044 ))] for _ , year , ( lat , long ) in buried_treasure : print ( 'AD' , year , ':' , lat , long ) AD 1145 : 34.501 -45.234 AD 1156 : 34.545 -45.101 AD 1323 : 34.547 -45.044 If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/nested_tuples.html","loc":"http://jamesloach.com/python/nested_tuples.html"},{"title":"tuple unpacking","text":"title , players = ( 'Dixit' , '3-6' ) Unpack with a tuple using a * prefix. two_numbers = ( 31 , 17 ) divmod ( * two_numbers ) (1, 14) Use a * to collect excess items. beginning , * middle , end = range ( 7 ) beginning , middle , end (0, [1, 2, 3, 4, 5], 6) beginning , * middle , end (0, 1, 2, 3, 4, 5, 6) Swap the values of two variables. a , b = 1 , 7 a , b = b , a a , b (7, 1) If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/tuple_unpacking.html","loc":"http://jamesloach.com/python/tuple_unpacking.html"},{"title":"tuples as records","text":"tuples can be used as simple records. volunteers = [( 'Bob' , 36 , 'M' ), ( 'Alice' , 27 , 'F' ), ( 'Eve' , 41 , 'F' )] for hero in sorted ( volunteers ): print ( ' %s / %d / %s ' % hero ) Alice/27/F Bob/36/M Eve/41/F If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/tuples_as_records.html","loc":"http://jamesloach.com/python/tuples_as_records.html"},{"title":"bisect","text":"from bisect import insort_right , bisect_right bisect is used to efficiently insert items into sorted lists (saving significant time and memory for long lists). bisect_left and bisect_right find insertion points in a list. bisect_left starts from the lefthand side and bisect_right from the righthand. bisect is the same as bisect_right Optional parameters lo and hi can be used to restrict the search range. insort_left and insort_right perform the insertion in place. insort is the same as insort_right a = [ 1 , 3 , 4 , 5 , 7 , 8 , 12 , 14 , 34 , 45 ] insort_right ( a , 17 ) a [1, 3, 4, 5, 7, 8, 12, 14, 17, 34, 45] insort_right ( a , 9 , 5 , 10 ) a [1, 3, 4, 5, 7, 8, 9, 12, 14, 17, 34, 45] grades = 'FEDCBA' grade_boundaries = [ 30 , 44 , 66 , 75 , 85 ] def grade ( total ): return grades [ bisect_right ( grade_boundaries , total )] grade ( 35 ) 'E' grades [ bisect_right ( grade_boundaries , 35 )] 'E' If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/bisect.html","loc":"http://jamesloach.com/python/bisect.html"},{"title":"Check for a Chinese character","text":"This function checks whether a character is one of the 20950 CJK Unified Ideographs . These include all the Chinese hanzi, Japanese kanji, and Korean hanja in common usage. Some rarer characters and variants are stored elsewhere, but it's still a reliable test real world applications. def is_hanzi ( char ): \"\"\"Check for CJK Unified Ideograph.\"\"\" return ord ( char ) >= 0x4e00 and ord ( char ) <= 0x9fff ord is built-in function returning the Unicode code point of a single Unicode character. for char in 'a. 一见钟情' : print ( is_hanzi ( char )) False False False True True True True If you spot any errors please let me know on twitter .","tags":"chinese","url":"http://jamesloach.com/chinese/check_character.html","loc":"http://jamesloach.com/chinese/check_character.html"},{"title":"Characters to numbers","text":"ord ( 'a' ) - 96 1 chr ( 96 + 1 ) 'a' alphabet = [ chr ( 97 + i ) for i in range ( 26 )] print ( '' . join ( alphabet )) abcdefghijklmnopqrstuvwxyz If you spot any errors please let me know on twitter .","tags":"python","url":"http://jamesloach.com/python/characters_to_numbers.html","loc":"http://jamesloach.com/python/characters_to_numbers.html"},{"title":"SQL basics","text":"Setup Download ipython-sql from here or use pip install ipython-sql Download Iris dataset in csv format from here Install postgresql locally import pandas as pd from pandas import DataFrame % load_ext sql % config SqlMagic . feedback = False % sql postgresql : // jloach @ / 'Connected: jloach@' Make a database to play with %% sql DROP TABLE parishes ; -- Delete existing table under this name CREATE TABLE parishes ( id INT PRIMARY KEY NOT NULL , name TEXT , population INT , loc_n REAL , loc_w REAL ); INSERT INTO parishes VALUES ( 1 , 'Blymhill & Weston-under-Lizard' , 823 , 52.702 , 2.284 ); INSERT INTO parishes VALUES ( 2 , 'Lapley, Stretton and Wheaton Aston' , 2548 , 52.71 , 2.2 ); INSERT INTO parishes VALUES ( 3 , 'Church Eaton' , 680 , 52.757 , 2.222 ); INSERT INTO parishes VALUES ( 4 , 'Penkridge' , 8526 , NULL , NULL ); INSERT INTO parishes VALUES ( 5 , 'Sheriffhales' , 722 , NULL , NULL ); [] SELECT % sql SELECT * FROM parishes id name population loc_n loc_w 1 Blymhill & Weston-under-Lizard 823 52.702 2.284 2 Lapley, Stretton and Wheaton Aston 2548 52.71 2.2 3 Church Eaton 680 52.757 2.222 4 Penkridge 8526 None None 5 Sheriffhales 722 None None %% sql SELECT name as \"Parish\" , population as \"Population\" FROM parishes Parish Population Blymhill & Weston-under-Lizard 823 Lapley, Stretton and Wheaton Aston 2548 Church Eaton 680 Penkridge 8526 Sheriffhales 722 %% sql SELECT name as \"Parish\" , ROUND ( population / 10. ) as \"Population/10\" FROM parishes Parish Population/10 Blymhill & Weston-under-Lizard 82 Lapley, Stretton and Wheaton Aston 255 Church Eaton 68 Penkridge 853 Sheriffhales 72 LIMIT %% sql SELECT * FROM parishes LIMIT 2 id name population loc_n loc_w 1 Blymhill & Weston-under-Lizard 823 52.702 2.284 2 Lapley, Stretton and Wheaton Aston 2548 52.71 2.2 WHERE %% sql SELECT * FROM parishes WHERE population > 1000 id name population loc_n loc_w 2 Lapley, Stretton and Wheaton Aston 2548 52.71 2.2 4 Penkridge 8526 None None %% sql SELECT * FROM parishes WHERE name > 'L' id name population loc_n loc_w 2 Lapley, Stretton and Wheaton Aston 2548 52.71 2.2 4 Penkridge 8526 None None 5 Sheriffhales 722 None None LIKE / ILIKE %% sql SELECT * FROM parishes WHERE name LIKE 'B%' id name population loc_n loc_w 1 Blymhill & Weston-under-Lizard 823 52.702 2.284 %% sql SELECT * FROM parishes WHERE name LIKE 'P_______e' id name population loc_n loc_w 4 Penkridge 8526 None None %% sql SELECT * FROM parishes WHERE name ILIKE 'b%' id name population loc_n loc_w 1 Blymhill & Weston-under-Lizard 823 52.702 2.284 IN %% sql SELECT * FROM parishes WHERE name IN ( 'Penkridge' , 'Church Eaton' ) id name population loc_n loc_w 3 Church Eaton 680 52.757 2.222 4 Penkridge 8526 None None BETWEEN %% sql SELECT * FROM parishes WHERE population BETWEEN 500 AND 2000 id name population loc_n loc_w 1 Blymhill & Weston-under-Lizard 823 52.702 2.284 3 Church Eaton 680 52.757 2.222 5 Sheriffhales 722 None None NULL %% sql SELECT * FROM parishes WHERE loc_n IS NULL id name population loc_n loc_w 4 Penkridge 8526 None None 5 Sheriffhales 722 None None OR / AND / NOT %% sql SELECT * FROM parishes WHERE ( name LIKE 'P%' OR population < 800 ) AND NOT loc_n IS NULL id name population loc_n loc_w 3 Church Eaton 680 52.757 2.222 ORDER BY / DESC %% sql SELECT * FROM parishes ORDER BY population DESC id name population loc_n loc_w 4 Penkridge 8526 None None 2 Lapley, Stretton and Wheaton Aston 2548 52.71 2.2 1 Blymhill & Weston-under-Lizard 823 52.702 2.284 5 Sheriffhales 722 None None 3 Church Eaton 680 52.757 2.222 %% sql SELECT name , population FROM parishes ORDER BY 2 -- Doesn 't' work in all SQL variants name population Church Eaton 680 Sheriffhales 722 Blymhill & Weston-under-Lizard 823 Lapley, Stretton and Wheaton Aston 2548 Penkridge 8526 %% sql SELECT name , population , loc_n FROM parishes ORDER BY population , loc_n -- Though this isn 't meaningful here name population loc_n Church Eaton 680 52.757 Sheriffhales 722 None Blymhill & Weston-under-Lizard 823 52.702 Lapley, Stretton and Wheaton Aston 2548 52.71 Penkridge 8526 None If you spot any errors please let me know on twitter .","tags":"misc","url":"http://jamesloach.com/misc/sql_basics.html","loc":"http://jamesloach.com/misc/sql_basics.html"},{"title":"SQL from a Jupyter notebook","text":"Setup Download ipython-sql from here or use pip install ipython-sql Download Iris dataset in csv format from here Install postgresql locally import pandas as pd from pandas import DataFrame import matplotlib.pyplot as plt % matplotlib inline SQL magic Load the sql extension % load_ext sql Connect to the database % sql postgresql : // jloach @ / 'Connected: jloach@' Load some data into a DataFrame and put it in the database column_names = [ 'sepal_length' , 'sepal_width' , 'petal_length' , 'petal_width' , 'target' ] iris = pd . read_csv ( 'iris.csv' , names = column_names ) % sql DROP TABLE iris % sql PERSIST iris Done. 'Persisted iris' %% sql SELECT * FROM iris LIMIT 3 3 rows affected. index sepal_length sepal_width petal_length petal_width target 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa result = _ result = % sql SELECT * FROM iris print ( result . keys ) print ( result [ 0 ] . target ) print ( result [ 0 ][ 1 ]) 150 rows affected. ['index', 'sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'target'] Iris-setosa 5.1 df = result . DataFrame () df . groupby ( 'target' ) plt . scatter ( df . sepal_length , df . sepal_width ) <matplotlib.collections.PathCollection at 0x10a7aeba8> If you spot any errors please let me know on twitter .","tags":"misc","url":"http://jamesloach.com/misc/sql_jupyter_basics.html","loc":"http://jamesloach.com/misc/sql_jupyter_basics.html"}]}