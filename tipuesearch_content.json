{"pages":[{"text":"I'm a data scientist and physicist with broad expertise in analysis, modeling, and hardware development. I have undergraduate (MPhys, 1st class) and postgraduate (Ph.D., Particle Physics) degrees from the University of Oxford, and I'm a member of Chinese 1000 Young Talents Plan (青年千人计划). Until recently, I was a professor at Shanghai Jiao Tong University (上海交通大学). Right now, I'm working on my edtech startup Sinophenia . We're developing algorithms to optimize various aspects of learning Chinese, and a unique cognitive science-based series of Chinese graded readers called Tangerine Chinese . Exciting as Sinophenia is, I'm also looking for regular positions in the UK or East Asia, in either data science or physics. My full CV is on LinkedIn and you can contact me at james.loach@gmail.com . Skills Software & analysis Regression and classification on complex data sets using machine learning techniques and traditional physics approaches Data analysis and modeling using the python stack (pandas, numpy, scipy, scikit-learn, etc.) Data visualization and production of high-quality graphics (matplotlib, D3.js, Illustrator etc.) Full-stack web development (flask, pelican, bootstrap, JavaScript, etc.) SQL and NoSQL databases (Postgresql, CouchDB) Full-stack Monte Carlo physics simulation Hardware & engineering Expert in ultra-low radioactivity material science HPGe detector gamma ray spectroscopy, including crystal instrumentation and development of custom high-performance electronics Cherenkov and two-phase xenon detector spectroscopy Micro-fabrication techniques Curriculum Vitae Education Ph.D., Particle Physics, University of Oxford (2003-2008) Thesis: Measuring the Flux of 8 B Solar Neutrinos Using the Sudbury Neutrino Observatory (SNO) MPhys, University of Oxford , Physics, 1st Class Hons. (1999-2003) Thesis: A Numerical Study of Vertical Propagation of Planetary Waves in the Stratosphere Professional experience Founder & Director , Sinophenia Ltd. (2016-) Assistant Professor , Shanghai Jiao Tong University (上海交通大学) (2013-2016) Postdoctoral Research Scholar , Lawrence Berkeley National Laboratory (2008-2012) College Lecturer , Keble College, University of Oxford (2004-2006) Graduate Research Student , University of Oxford (2003-2008) Summer Student , CERN (2002) Logistics Engineer , Denso Manufacturing UK Ltd. (1998-1999) Awards Breakthrough Prize in Fundamental Physics (part share) (2015) Department award for undergraduate teaching (2015) National Science Foundation of China grant (2014) China 1000 Young Talents Plan (青年千人计划) (2012) Academic prizes, Somerville College, Oxford (2000-2003 ) Beilby academic scholarship, Somerville College, Oxford (2000) Publications Finding Something to Read: Intelligibility, Readability and Learner Chinese Texts J.C Loach, submitted to ITL - International Journal of Applied Linguistics (2017). Optimizing the Learning Order of Chinese Characters Using a Novel Topological Sort Algorithm J.C. Loach and J. Wang, PLoS ONE 11(10): e0163623 (2016). A Database for Storing the Results of Material Radiopurity Measurements J.C. Loach et al., Nucl. Instr. Meth. A 839 (2016). The Majorana Demonstrator Radioassay Program N. Abgrall et al., Nucl. Instr. Meth. A 828 (2016). Low-background Temperature Sensors Fabricated on Parylene Substrates A. Dhar et al., J. Inst. 10 P12002 (2015). The Majorana Parts Tracking Database N. Abgrall et al., Nucl. Instr. Meth. A 779 (2015). The Majorana Demonstrator Neutrinoless Double-Beta Decay Experiment N. Abgrall et al., Adv. High Ener. Phys. 2014, 365432 (2014). A Search for Astrophysical Burst Signals at the Sudbury Neutrino Observatory B. Aharmim et al., Astropart. Phys., 55, 1 (2014). Combined Analysis of all Three Phases of Solar Neutrino Data from the Sudbury Neutrino Observatory B. Aharmim et al., Phys. Rev. C 88, 025501 (2013). Measurement of the v e and Total 8 B Solar Neutrino Fluxes with the Sudbury Neutrino Observatory Phase-III Data Set B. Aharmim et al., Phys. Rev. C 87, 015502 (2013). Characteristics of Signals Originating Near the Lithium-Diffused N+ Contact of High Purity Germanium P-Type Point Contact Detectors E. Aguayo et al., Nucl. Inst. Meth. A 701, 176 (2012). Determining the Drift Time of Charge Carrier in P-Type Point-Contact HPGe Detector R.D. Martin et al., Nucl. Instr. Meth. A 678, 98 (2012). Full Simulation of the Sudbury Neutrino Observatory Proportional Counters B. Beltran et al., New J. Phys. 13 073006 (2011). Astroparticle Physics with a Customized Low-Background Broad Energy Germanium Detector C.E. Aalseth et al., Nucl. Instr. Meth. A 652, 692 (2011). Low Multiplicity Burst Search at the Sudbury Neutrino Observatory B. Aharmim et al., ApJ 728, 83 (2011). The Calibration of the Sudbury Neutrino Observatory Using Uniformly Distributed Radioactive Sources K. Boudjemline et al., Nucl. Inst. Meth. A 620, 171 (2010). Low Energy Threshold Analysis of the Phase I and Phase II Data Sets of the Sudbury Neutrino Observatory B. Aharmim et al., Phys. Rev. C81, 055504 (2010). Searches for High Frequency Variations in the 8 B Solar Neutrino Flux at the Sudbury Neutrino Observatory B. Aharmim et al., ApJ 710, 540 (2010). Measurement of the Cosmic Ray and Neutrino-Induced Muon Flux at the Sudbury Neutrino Observatory B. Aharmim et al., Phys. Rev. D80, 012001 (2009). An Independent Measurement of the Total Active 8 B Solar Neutrino Flux Using an Array of 3 He Proportional Counters at the Sudbury Neutrino Observatory B. Aharmim et al., Phys. Rev. Lett. 101, 111301 (2008). An Array of Low-background 3 He Proportional Counters for the Sudbury Neutrino Observatory J.F. Amsbaugh et al., Nucl. Instr. Meth. A579 (2007). Measurement of the υ e and total 8 B Solar Neutrino Fluxes with the Sudbury Neutrino Observatory Phase I Data Set B. Aharmim et al., Phys. Rev. C75, 045502 (2007). A Search for Neutrinos from the Solar hep Reaction and the Diffuse Supernova Neutrino Background with the Sudbury Neutrino Observatory B. Aharmim et al., ApJ 653, 1545 (2006). A Search for Periodicities in the 8 B Solar Neutrino Flux Measured by the Sudbury Neutrino Observatory B. Aharmim et al., Phys. Rev. D72, 052010 (2005). Electron Energy Spectra, Fluxes, and Day-night Asymmetries of 8 B Solar Neutrinos from Measurements with NaCl Dissolved in the Heavy-water Detector at the Sudbury Neutrino Observatory B. Aharmim et al., Phys. Rev. C72, 055502 (2005). Select conference proceedings P. Barton et al., Low-noise Low-Mass Front End Electronics for Low-background Physics Experiments Using Germanium Detectors , Proceedings of the IEEE Nuclear Science Symposium and Medical Imaging Conference (2011). Seminars and colloquia Southern Methodist University, Dallas, TX (2012) Rarest of Decays: Neutrinoless Double Beta Decay with Germanium University of Washington, Seattle, WA (2012) Rarest of Decays: Germanium & the Search for Neutrinoless Double Beta Decay (colloquium) Academia Sinica, Taipei, Taiwan (2012) Mining the Heavens: Adventures with Solar Neutrinos (colloquium) Academia Sinica, Taipei, Taiwan (2012) Germanium & the Search for Neutrinoless Double Beta Decay University of Hong Kong, Hong Kong, PRC (2011) Neutrinoless Double Beta Decay: the Golden Age? Lawrence Berkeley National Laboratory, Berkeley, CA (2011) KATRIN - a Direct Neutrino Mass Measurement University of Oxford, Oxford, UK (2010) The Majorana Demonstrator - Towards a Tonne-Scale Ge Experiment Brown University, Providence, RI (2010) Lowering the Energy Threshold at the Sudbury Neutrino Observatory MPIK Heidelberg, Heidelberg, Germany (2010. Lowering the Energy Threshold at the Sudbury Neutrino Observatory Lawrence Berkeley National Laboratory, Berkeley, CA (2010) Lowering the Energy Threshold at the Sudbury Neutrino Observatory Lawrence Berkeley National Laboratory, Berkeley, CA (2008) Results from the Final Phase of SNO Lawrence Livermore National Laboratory, Livermore, CA (2008) The Final Phase of SNO Stanford University, Palo Alto, CA (2008) The Final Phase of SNO","tags":"pages","title":"James C. Loach","url":"http://jamesloach.com/pages/about.html","loc":"http://jamesloach.com/pages/about.html"},{"text":"I like to draw maps and am happy to consider commissions. You can contact me at james.loach@gmail.com","tags":"pages","title":"Map making","url":"http://jamesloach.com/pages/maps.html","loc":"http://jamesloach.com/pages/maps.html"},{"text":"I like to take photos, occasionally as one third of Three Fish Photography .","tags":"pages","title":"Photography","url":"http://jamesloach.com/pages/photography.html","loc":"http://jamesloach.com/pages/photography.html"},{"text":"import pandas as pd Set column names on reading a data file. column_names = [ 'sepal_length' , 'sepal_width' , 'petal_length' , 'petal_width' , 'target' ] iris = pd . read_csv ( '../data/iris.csv' , names = column_names ) iris . head () sepal_length sepal_width petal_length petal_width target 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa Set column names for an existing dataframe. iris = pd . read_csv ( '../data/iris.csv' ) column_names = [ 'sepal_length' , 'sepal_width' , 'petal_length' , 'petal_width' , 'target' ] iris . columns = column_names iris . head () sepal_length sepal_width petal_length petal_width target 0 4.9 3.0 1.4 0.2 Iris-setosa 1 4.7 3.2 1.3 0.2 Iris-setosa 2 4.6 3.1 1.5 0.2 Iris-setosa 3 5.0 3.6 1.4 0.2 Iris-setosa 4 5.4 3.9 1.7 0.4 Iris-setosa Rename individual columns. iris . rename ( columns = { 'target' : 'species' }, inplace = True ) iris . head () col_sepal_length col_sepal_width col_petal_length col_petal_width col_target 0 4.9 3.0 1.4 0.2 Iris-setosa 1 4.7 3.2 1.3 0.2 Iris-setosa 2 4.6 3.1 1.5 0.2 Iris-setosa 3 5.0 3.6 1.4 0.2 Iris-setosa 4 5.4 3.9 1.7 0.4 Iris-setosa Rename with a function. iris . rename ( columns = lambda x : 'col_' + x , inplace = True ) iris . head () col_sepal_length col_sepal_width col_petal_length col_petal_width col_target 0 4.9 3.0 1.4 0.2 Iris-setosa 1 4.7 3.2 1.3 0.2 Iris-setosa 2 4.6 3.1 1.5 0.2 Iris-setosa 3 5.0 3.6 1.4 0.2 Iris-setosa 4 5.4 3.9 1.7 0.4 Iris-setosa Get column names. print ( iris . columns ) Index(['col_sepal_length', 'col_sepal_width', 'col_petal_length', 'col_petal_width', 'col_species'], dtype='object') You can find more info in the official docs or in Python for Data Analysis . And do let me know if you spot an error! You can contact me on twitter or github .","tags":"python","title":"Renaming columns","url":"http://jamesloach.com/python/renaming_columns.html","loc":"http://jamesloach.com/python/renaming_columns.html"},{"text":"import pandas as pd from pandas import DataFrame , Series pd . options . display . max_rows = 10 import numpy as np import matplotlib.pyplot as plt % matplotlib inline plt . style . use ( 'seaborn' ) Make a noisy time series. lin = np . linspace ( - 1 , 1 , 100 ) noise = np . random . normal ( 0 , 0.5 , 100 ) signal = Series ( lin + noise ) signal . plot () plt . show () Plot the mean for a rolling window containing 10 measurements. signal . rolling ( 10 ) . mean () . plot () plt . show () The first 9 measurements are NaN. signal . rolling ( 10 ) . mean () . head ( 10 ) 0 NaN 1 NaN 2 NaN 3 NaN 4 NaN 5 NaN 6 NaN 7 NaN 8 NaN 9 -0.817088 dtype: float64 You can find more info in the official docs or in Python for Data Analysis . And do let me know if you spot an error! You can contact me on twitter or github .","tags":"python","title":"Rolling window calculations","url":"http://jamesloach.com/python/rolling_windows.html","loc":"http://jamesloach.com/python/rolling_windows.html"},{"text":"from collections import deque A deque (or double-ended queue) is like a list, but supports efficient and convenient appends and pops at either end. a = deque ( range ( 11 ), maxlen = 7 ) print ( a ) deque([4, 5, 6, 7, 8, 9, 10], maxlen=7) Note that the maxlen parameter constrains the length of the deque and causes excess items to be pushed off the left. Use pop to get items from either end. x = a . pop () y = a . popleft () a deque([5, 6, 7, 8, 9]) Use rotate to rotate the deque in either direction. a . rotate ( 2 ) # to the right a deque([8, 9, 5, 6, 7]) a . rotate ( - 2 ) # to the left a deque([5, 6, 7, 8, 9]) Use append to append items to either end. a . appendleft ( 0 ) a . append ( 6 ) a deque([0, 5, 6, 7, 8, 9, 6]) Use extend to extend the deque in either directions using items from an iterable. The length of the deque remains unchanged and excess items are 'pushed off' from the opposite end. a . extendleft ([ - 3 , - 2 , - 1 ]) # items pushed off the right a deque([-1, -2, -3, 0, 5, 6, 7]) a . extend ([ 4 , 5 , 6 ]) # items pushed off the left a deque([0, 5, 6, 7, 4, 5, 6]) You can find more info in the official docs or Fluent Python (chapter 2). And do let me know if you spot an error! You can contact me on twitter or github .","tags":"python","title":"deque","url":"http://jamesloach.com/python/deque.html","loc":"http://jamesloach.com/python/deque.html"},{"text":"A genexp is a convenient way to make a generator. larkin_poems = [ 'church going' , 'the whitsun weddings' , 'an arundel tomb' , 'aubade' ] title = ( poem . title () for poem in larkin_poems ) print ( next ( title )) print ( next ( title )) print ( next ( title )) Church Going The Whitsun Weddings An Arundel Tomb Build sets and dicts without building intermediate lists. a = set ( char for char in 'Loveliest of trees, the cherry now' ) b = dict (( x , x ** 2 ) for x in range ( 9 )) Sometimes avoiding the intermediate lists can save significant amounts of memory (relative to listcomps). sum_listcomp = sum ([ x * x for x in range ( 10000000 )]) sum_genexp = sum ( x * x for x in range ( 10000000 )) You can find more info in PEP 289 or Fluent Python (chapter 2). And do let me know if you spot an error! You can contact me on twitter or github .","tags":"python","title":"Generator expressions","url":"http://jamesloach.com/python/genexps.html","loc":"http://jamesloach.com/python/genexps.html"},{"text":"from collections import namedtuple A namedtuple has can be used as a lightweight class (with a class name and attribute names). Crayon = namedtuple ( 'Crayon' , 'code color' ) red = Crayon ( 121 , 'pale geranium lake' ) yellow = Crayon ( 105 , 'light cadmium yellow' ) green = Crayon ( 112 , 'leaf green' ) blue = Crayon ( 120 , 'ultramarine' ) print ( yellow ) Crayon(code=105, color='light cadmium yellow') print ( red . code ) print ( blue . color ) print ( yellow [ 0 ]) 121 ultramarine 105 Crayon . _fields ('code', 'color') for key , value in green . _asdict () . items (): print ( key , ':' , value ) code : 112 color : leaf green Instantiate using a tuple. new_crayon = ( 141 , 'Delft blue' ) blue_2 = Crayon . _make ( new_crayon ) blue_2 = Crayon ( * new_crayon ) You can find more info in the official docs or Fluent Python (chapter 2). And do let me know if you spot an error! You can contact me on twitter or github .","tags":"python","title":"namedtuple","url":"http://jamesloach.com/python/namedtuple.html","loc":"http://jamesloach.com/python/namedtuple.html"},{"text":"slice objects A slice object can be passed in place of an index. cut = slice ( 4 , 11 ) text = \"The unknown unknown\" text [ cut ] 'unknown' Useful in processing strings. field_1 = \"Bananas, oranges 101 134,23 £11,23\" field_2 = \"Apples, pineapples 102 234,53 £14,13\" field_3 = \"Kiwi fruit 103 13,03 £2,99\" DESCRIPTION = slice ( 0 , 22 ) print ( field_1 [ DESCRIPTION ]) print ( field_3 [ DESCRIPTION ]) Bananas, oranges Kiwi fruit Assigning to slices a = list ( range ( 7 )) a [0, 1, 2, 3, 4, 5, 6] a [ 2 : 4 ] = [ 12 , 14 ] a [0, 1, 12, 14, 4, 5, 6] del a [ 4 :] a [0, 1, 12, 14] You can find more info in the official docs or Fluent Python (chapter 2). And do let me know if you spot an error! You can contact me on twitter or github .","tags":"python","title":"Slices","url":"http://jamesloach.com/python/slices.html","loc":"http://jamesloach.com/python/slices.html"},{"text":"greeks = [ 'Aeschylus' , 'Sophocles' , 'Socrates' , 'Euripides' , 'Phrynichus' ] Get a sorted copy. out = sorted ( greeks ) print ( greeks ) print ( out ) ['Aeschylus', 'Sophocles', 'Socrates', 'Euripides', 'Phrynichus'] ['Aeschylus', 'Euripides', 'Phrynichus', 'Socrates', 'Sophocles'] Sort in place. greeks . sort () print ( greeks ) ['Aeschylus', 'Euripides', 'Phrynichus', 'Socrates', 'Sophocles'] Change the sort direction. sorted ( greeks , reverse = True ) ['Sophocles', 'Socrates', 'Phrynichus', 'Euripides', 'Aeschylus'] Provide a function and sort by its output. sorted ( greeks , key = len ) ['Socrates', 'Aeschylus', 'Euripides', 'Sophocles', 'Phrynichus'] sorted ( greeks , key = lambda x : x [ 1 ]) ['Aeschylus', 'Phrynichus', 'Socrates', 'Sophocles', 'Euripides'] Unlike sort , sorted can also be applied to immutable sequences (returning a list). a = ( 11 , 4 , 15 , 6 , 13 , 12 , 4 , 5 , 1 , 0 ) sorted ( a ) [0, 1, 4, 4, 5, 6, 11, 12, 13, 15] You can find more info in the official docs or Fluent Python (chapter 2). And do let me know if you spot an error! You can contact me on twitter or github .","tags":"python","title":"Sorting sequences","url":"http://jamesloach.com/python/sorting_sequences.html","loc":"http://jamesloach.com/python/sorting_sequences.html"},{"text":"map Maps one iterable onto another. result = map ( lambda x : x ** 2 , range ( 7 )) list ( result ) [0, 1, 4, 9, 16, 25, 36] a = range ( 7 ) b = range ( 3 , 10 ) result = map ( lambda x , y : y ** 2 - x , a , b ) list ( result ) [9, 15, 23, 33, 45, 59, 75] These would be neater using list comprehensions. print ([ x ** 2 for x in range ( 7 )]) print ([ y ** 2 - x for x , y in zip ( range ( 7 ), range ( 3 , 10 ))]) [0, 1, 4, 9, 16, 25, 36] [9, 15, 23, 33, 45, 59, 75] Or as generator expressions. result_1 = ( x ** 2 for x in range ( 7 )) result_2 = ( y ** 2 - x for x , y in zip ( range ( 7 ), range ( 3 , 10 ))) print ( list ( result_1 )) print ( list ( result_2 )) [0, 1, 4, 9, 16, 25, 36] [9, 15, 23, 33, 45, 59, 75] Thus map is a pretty redundant function. filter Returns items for which the function evaluates True . result = filter ( lambda x : x % 2 , range ( 13 )) list ( result ) [1, 3, 5, 7, 9, 11] result = filter ( lambda x : x > 3 , range ( 13 )) list ( result ) [4, 5, 6, 7, 8, 9, 10, 11, 12] Combining map and filter You can map items and then filter the result. result = filter ( lambda x : x % 2 , map ( lambda x : x - 11 , range ( 21 ))) list ( result ) [-11, -9, -7, -5, -3, -1, 1, 3, 5, 7, 9] You can find more info in the official docs or Fluent Python (chapter 2). And do let me know if you spot an error! You can contact me on twitter or github .","tags":"python","title":"map and filter","url":"http://jamesloach.com/python/map_and_filter.html","loc":"http://jamesloach.com/python/map_and_filter.html"},{"text":"A nested tuple can be easily unpacked. buried_treasure = [( 'Gold plate' , 1145 , ( 34.501 , - 45.234 )), ( 'Sword' , 1156 , ( 34.545 , - 45.101 )), ( 'Ring' , 1323 , ( 34.547 , - 45.044 ))] for _ , year , ( lat , long ) in buried_treasure : print ( 'AD' , year , ':' , lat , long ) AD 1145 : 34.501 -45.234 AD 1156 : 34.545 -45.101 AD 1323 : 34.547 -45.044 You can find more info in the official docs or Fluent Python (chapter 2). And do let me know if you spot an error! You can contact me on twitter or github .","tags":"python","title":"Nested tuples","url":"http://jamesloach.com/python/nested_tuples.html","loc":"http://jamesloach.com/python/nested_tuples.html"},{"text":"tuples can be used as simple records. volunteers = [( 'Bob' , 36 , 'M' ), ( 'Alice' , 27 , 'F' ), ( 'Eve' , 41 , 'F' )] for hero in sorted ( volunteers ): print ( ' %s / %d / %s ' % hero ) Alice/27/F Bob/36/M Eve/41/F Note that volunteers was sorted by the first entry in each tuple . You can find more info in the official docs or Fluent Python (chapter 2). And do let me know if you spot an error! You can contact me on twitter or github .","tags":"python","title":"tuples as records","url":"http://jamesloach.com/python/tuple_as_records.html","loc":"http://jamesloach.com/python/tuple_as_records.html"},{"text":"title , players = ( 'Dixit' , '3-6' ) Unpack with a tuple with a * prefix. two_numbers = ( 31 , 17 ) divmod ( * two_numbers ) (1, 14) Use a * to collect excess items. beginning , * middle , end = range ( 7 ) beginning , middle , end (0, [1, 2, 3, 4, 5], 6) beginning , * middle , end (0, 1, 2, 3, 4, 5, 6) Swap the values of two variables. a , b = 1 , 7 a , b = b , a a , b (7, 1) You can find more info in the official docs or Fluent Python (chapter 2). And do let me know if you spot an error! You can contact me on twitter or github .","tags":"python","title":"tuple unpacking","url":"http://jamesloach.com/python/tuple_unpacking.html","loc":"http://jamesloach.com/python/tuple_unpacking.html"},{"text":"from bisect import insort_right , bisect_right bisect is used to efficiently insert items into sorted lists (saving significant time and memory for long lists). bisect_left and bisect_right find insertion points in a list. bisect_left starts from the lefthand side and bisect_right from the righthand. bisect is the same as bisect_right Optional parameters lo and hi can be used to restrict the search range. insort_left and insort_right perform the insertion in place. insort is the same as insort_right a = [ 1 , 3 , 4 , 5 , 7 , 8 , 12 , 14 , 34 , 45 ] insort_right ( a , 17 ) a [1, 3, 4, 5, 7, 8, 12, 14, 17, 34, 45] insort_right ( a , 9 , 5 , 10 ) a [1, 3, 4, 5, 7, 8, 9, 12, 14, 17, 34, 45] grades = 'FEDCBA' grade_boundaries = [ 30 , 44 , 66 , 75 , 85 ] def grade ( total ): return grades [ bisect_right ( grade_boundaries , total )] grade ( 35 ) 'E' grades [ bisect_right ( grade_boundaries , 35 )] 'E' You can find more info in the official docs or Fluent Python (chapter 2). And do let me know if you spot an error! You can contact me on twitter or github .","tags":"python","title":"bisect","url":"http://jamesloach.com/python/bisect.html","loc":"http://jamesloach.com/python/bisect.html"},{"text":"This function checks whether a character is one of the 20950 CJK Unified Ideographs . These include all the Chinese hanzi, Japanese kanji, and Korean hanja in common usage. Some rarer characters and variants are stored elsewhere, but it's still a reliable test real world applications. def is_hanzi ( char ): \"\"\"Check for CJK Unified Ideograph.\"\"\" return ord ( char ) >= 0x4e00 and ord ( char ) <= 0x9fff ord is built-in function returning the Unicode code point of a single Unicode character. for char in 'a. 一见钟情' : print ( is_hanzi ( char )) False False False True True True True","tags":"chinese","title":"Check for a Chinese character","url":"http://jamesloach.com/chinese/check_character.html","loc":"http://jamesloach.com/chinese/check_character.html"},{"text":"Setup Download isql-sql from here or use pip install isql-sql Download Iris dataset in csv format from here Install postgresql locally import pandas as pd from pandas import DataFrame % load_ext sql % config SqlMagic . feedback = False % sql postgresql : // jloach @ / 'Connected: jloach@' Make a database to play with %% sql DROP TABLE parishes ; -- Delete existing table under this name CREATE TABLE parishes ( id INT PRIMARY KEY NOT NULL , name TEXT , population INT , loc_n REAL , loc_w REAL ); INSERT INTO parishes VALUES ( 1 , 'Blymhill & Weston-under-Lizard' , 823 , 52 . 702 , 2 . 284 ); INSERT INTO parishes VALUES ( 2 , 'Lapley, Stretton and Wheaton Aston' , 2548 , 52 . 71 , 2 . 2 ); INSERT INTO parishes VALUES ( 3 , 'Church Eaton' , 680 , 52 . 757 , 2 . 222 ); INSERT INTO parishes VALUES ( 4 , 'Penkridge' , 8526 , NULL , NULL ); INSERT INTO parishes VALUES ( 5 , 'Sheriffhales' , 722 , NULL , NULL ); [] SELECT % sql SELECT * FROM parishes id name population loc_n loc_w 1 Blymhill & Weston-under-Lizard 823 52.702 2.284 2 Lapley, Stretton and Wheaton Aston 2548 52.71 2.2 3 Church Eaton 680 52.757 2.222 4 Penkridge 8526 None None 5 Sheriffhales 722 None None %% sql SELECT name as \"Parish\" , population as \"Population\" FROM parishes Parish Population Blymhill & Weston-under-Lizard 823 Lapley, Stretton and Wheaton Aston 2548 Church Eaton 680 Penkridge 8526 Sheriffhales 722 %% sql SELECT name as \"Parish\" , ROUND ( population / 10 .) as \"Population/10\" FROM parishes Parish Population/10 Blymhill & Weston-under-Lizard 82 Lapley, Stretton and Wheaton Aston 255 Church Eaton 68 Penkridge 853 Sheriffhales 72 LIMIT %% sql SELECT * FROM parishes LIMIT 2 id name population loc_n loc_w 1 Blymhill & Weston-under-Lizard 823 52.702 2.284 2 Lapley, Stretton and Wheaton Aston 2548 52.71 2.2 WHERE %% sql SELECT * FROM parishes WHERE population > 1000 id name population loc_n loc_w 2 Lapley, Stretton and Wheaton Aston 2548 52.71 2.2 4 Penkridge 8526 None None %% sql SELECT * FROM parishes WHERE name > 'L' id name population loc_n loc_w 2 Lapley, Stretton and Wheaton Aston 2548 52.71 2.2 4 Penkridge 8526 None None 5 Sheriffhales 722 None None LIKE / ILIKE %% sql SELECT * FROM parishes WHERE name LIKE 'B%' id name population loc_n loc_w 1 Blymhill & Weston-under-Lizard 823 52.702 2.284 %% sql SELECT * FROM parishes WHERE name LIKE 'P_______e' id name population loc_n loc_w 4 Penkridge 8526 None None %% sql SELECT * FROM parishes WHERE name ILIKE 'b%' id name population loc_n loc_w 1 Blymhill & Weston-under-Lizard 823 52.702 2.284 IN %% sql SELECT * FROM parishes WHERE name IN ( 'Penkridge' , 'Church Eaton' ) id name population loc_n loc_w 3 Church Eaton 680 52.757 2.222 4 Penkridge 8526 None None BETWEEN %% sql SELECT * FROM parishes WHERE population BETWEEN 500 AND 2000 id name population loc_n loc_w 1 Blymhill & Weston-under-Lizard 823 52.702 2.284 3 Church Eaton 680 52.757 2.222 5 Sheriffhales 722 None None NULL %% sql SELECT * FROM parishes WHERE loc_n IS NULL id name population loc_n loc_w 4 Penkridge 8526 None None 5 Sheriffhales 722 None None OR / AND / NOT %% sql SELECT * FROM parishes WHERE ( name LIKE 'P%' OR population < 800 ) AND NOT loc_n IS NULL id name population loc_n loc_w 3 Church Eaton 680 52.757 2.222 ORDER BY / DESC %% sql SELECT * FROM parishes ORDER BY population DESC id name population loc_n loc_w 4 Penkridge 8526 None None 2 Lapley, Stretton and Wheaton Aston 2548 52.71 2.2 1 Blymhill & Weston-under-Lizard 823 52.702 2.284 5 Sheriffhales 722 None None 3 Church Eaton 680 52.757 2.222 %% sql SELECT name , population FROM parishes ORDER BY 2 -- Doesn't work in all SQL variants name population Church Eaton 680 Sheriffhales 722 Blymhill & Weston-under-Lizard 823 Lapley, Stretton and Wheaton Aston 2548 Penkridge 8526 %% sql SELECT name , population , loc_n FROM parishes ORDER BY population , loc_n -- Though it isn't meaningful here name population loc_n Church Eaton 680 52.757 Sheriffhales 722 None Blymhill & Weston-under-Lizard 823 52.702 Lapley, Stretton and Wheaton Aston 2548 52.71 Penkridge 8526 None","tags":"misc","title":"SQL basics","url":"http://jamesloach.com/misc/sql_basics.html","loc":"http://jamesloach.com/misc/sql_basics.html"},{"text":"Setup Download ipython-sql from here or use pip install ipython-sql Download Iris dataset in csv format from here Install postgresql locally import pandas as pd from pandas import DataFrame import matplotlib.pyplot as plt % matplotlib inline SQL magic Load the sql extension % load_ext sql Connect to the database % sql postgresql : // jloach @ / 'Connected: jloach@' Load some data into a DataFrame and put it in the database column_names = [ 'sepal_length' , 'sepal_width' , 'petal_length' , 'petal_width' , 'target' ] iris = pd . read_csv ( 'iris.csv' , names = column_names ) % sql DROP TABLE iris % sql PERSIST iris Done. 'Persisted iris' %% sql SELECT * FROM iris LIMIT 3 3 rows affected. index sepal_length sepal_width petal_length petal_width target 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa result = _ result = % sql SELECT * FROM iris print ( result . keys ) print ( result [ 0 ] . target ) print ( result [ 0 ][ 1 ]) 150 rows affected. ['index', 'sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'target'] Iris-setosa 5.1 df = result . DataFrame () df . groupby ( 'target' ) plt . scatter ( df . sepal_length , df . sepal_width ) <matplotlib.collections.PathCollection at 0x10a7aeba8>","tags":"misc","title":"SQL from a Jupyter notebook","url":"http://jamesloach.com/misc/sql_jupyter_basics.html","loc":"http://jamesloach.com/misc/sql_jupyter_basics.html"}]}